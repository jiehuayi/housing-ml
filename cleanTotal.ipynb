{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixes the street formatting \n",
    "def fixAddress(address):\n",
    "    pattern = r'(\\d+)\\s+(st|nd|rd|th)\\b'\n",
    "    fixed = re.sub(pattern, r'\\1\\2', address, flags=re.IGNORECASE)\n",
    "    return fixed\n",
    "\n",
    "# removes apartment numbers\n",
    "def getStreetAddress(address):\n",
    "    dash = address.find('-')\n",
    "    comma = address.find(',')\n",
    "    if dash != -1:\n",
    "        street = address[dash+1:comma].strip()\n",
    "        return street\n",
    "    else:\n",
    "       return address[:comma].strip()\n",
    "\n",
    "def getPostalCode(address):\n",
    "    pattern = r', V\\d[A-Za-z](?: \\d[A-Za-z]\\d)?,'\n",
    "    match = re.search(pattern, address)\n",
    "    if match:\n",
    "        return match.group(0)[1:-1]\n",
    "    return None\n",
    "\n",
    "street_keywords = [\n",
    "    'street', 'st', 'str', 'road', 'rd', 'blvd', 'boulevard', 'ave', 'avenue', 'ln', 'lane',\n",
    "    'dr', 'drive', 'way', 'court', 'ct', 'pl', 'place', 'circle', 'cir', 'crescent', 'cr', \n",
    "    'terrace', 'ter', 'parkway', 'pkwy', 'square', 'sq', 'loop', 'highway', 'hwy', 'trail', \n",
    "]\n",
    "\n",
    "cities = ['Vancouver',\n",
    "         'Surrey',\n",
    "         'Langley', 'Township of Langley',\n",
    "         'Richmond',\n",
    "         'Burnaby',\n",
    "         'Delta',\n",
    "         'Pitt Meadows',\n",
    "         'New Westminster',\n",
    "         'White Rock',\n",
    "         'Coquitlam',\n",
    "         'Abbotsford',\n",
    "         'Maple Ridge']\n",
    "\n",
    "def getNeighborhood(row):\n",
    "    components = [comp.strip() for comp in row['addressDetails'].split(',')]\n",
    "    components_normalized = [comp.lower() for comp in components]\n",
    "    city_index = next((i for i, comp in enumerate(components_normalized) if any(city.lower() in comp for city in cities)), None)\n",
    "    if city_index is None:\n",
    "        return None\n",
    "    neighborhood = components[city_index - 1] if city_index > 0 else None\n",
    "\n",
    "    if neighborhood:\n",
    "        if any(keyword in neighborhood.lower().split(' ') for keyword in street_keywords) or any(char.isdigit() for char in neighborhood):\n",
    "            neighborhood = f\"General {row['city']} District\"\n",
    "\n",
    "    return neighborhood\n",
    "\n",
    "def getPropertyType(ptype):\n",
    "    if ptype in [3, 'Condo Apt', 'Apartment/Condominium']:\n",
    "        return 'Condo'\n",
    "    elif ptype in [4, 5, 'Duplex', 'Triplex', 'Multi Family']:\n",
    "        return 'MultiFamily'\n",
    "    elif ptype in [6, 'Cottage', 'Single Family Residence', 'Detached']:\n",
    "        return 'SingleFamily'\n",
    "    elif ptype == 8:\n",
    "        return 'Unknwon'\n",
    "    elif ptype in [13, 'Townhouse']:\n",
    "        return 'Townhouse'\n",
    "    return None\n",
    "\n",
    "def objToInt(col):\n",
    "    if pd.isna(col) or col == '':\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(re.sub(r'\\D', '', col))\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def objToFloat(col):\n",
    "    if pd.isna(col) or col == '':\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(re.sub(r'[^\\d.]', '', col))\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def makeAddress(street, city, province):\n",
    "    return f'{street}, {city}, {province}'\n",
    "\n",
    "def intToObj(col):\n",
    "    return object(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = ['mlsId', 'price', 'beds', 'baths', 'address', 'sqFt', 'parking', 'taxes', 'pricePerSqFt', 'yearBuilt', 'propertyType', 'soldDate', 'listingDate', 'listingPrice']\n",
    "select_columns_active = ['mlsId', 'beds', 'baths', 'address', 'sqFt', 'parking', 'taxes', 'pricePerSqFt', 'yearBuilt', 'propertyType', 'listingDate', 'listingPrice']\n",
    "\n",
    "def process_general_listing(df, out_path, sold=True):\n",
    "    df['address'] = df['address'].apply(fixAddress)\n",
    "    df['address'] = df['address'].apply(getStreetAddress) + f', {city}, BC, Canada'\n",
    "    df['listingPrice'] = df['listingPrice'].apply(objToFloat)\n",
    "    df['taxes'] = df['taxes'].apply(objToFloat)\n",
    "    df[['sqFt', 'pricePerSqFt']] = df[['sqFt', 'pricePerSqFt']].dropna().map(objToFloat)\n",
    "    df['propertyType'] = df['propertyType'].apply(getPropertyType)\n",
    "    if sold:\n",
    "        df['price'] = df['price'].apply(objToFloat)\n",
    "    df.dropna().to_csv(out_path, index=False)\n",
    "\n",
    "def process_active_listing(file_name, city, rename_mapping, select_columns):\n",
    "    file_path = f'./data/predict/{file_name}.csv'\n",
    "    df = pd.read_csv(file_path, dayfirst=True)\n",
    "    df = df.rename(columns=rename_mapping)[select_columns_active].dropna().drop_duplicates()\n",
    "    process_general_listing(df, f'./data/predict/ungeocoded/{city.lower()}-active-listings-ungeocoded.csv', sold=False)\n",
    "\n",
    "def process_listing(file_name, city, rename_mapping, select_columns):\n",
    "    file_path = f'./data/{file_name}.csv'\n",
    "    file_path_extra = f'./data/extra/{file_name}-extra.csv'\n",
    "    df = pd.read_csv(file_path, parse_dates=['soldDate', 'listingDate'], dayfirst=True)\n",
    "    df_extra = pd.read_csv(file_path_extra, parse_dates=['soldDate', 'listingDate'], dayfirst=True)\n",
    "    df = pd.concat([df, df_extra])\n",
    "    df = df.rename(columns=rename_mapping)[select_columns].dropna().drop_duplicates()\n",
    "    process_general_listing(df, f'./data/ungeocoded/{city.lower()}-listings-ungeocoded.csv')\n",
    "\n",
    "file_city_mapping = {\n",
    "    'vancouver-listings': 'Vancouver',\n",
    "    'surrey-listings': 'Surrey',\n",
    "    'langley-listings': 'Langley',\n",
    "    'richmond-listings': 'Richmond',\n",
    "    'burnaby-listings': 'Burnaby',\n",
    "    'delta-listings': 'Delta',\n",
    "    'pittMeadows-listings': 'Pitt Meadows',\n",
    "    'newWestminster-listings': 'New Westminster',\n",
    "    'whiteRock-listings': 'White Rock',\n",
    "    'coquitlam-listings': 'Coquitlam',\n",
    "    'abbotsford-listings': 'Abbotsford',\n",
    "    'mapleRidge-listings': 'Maple Ridge'\n",
    "}\n",
    "\n",
    "rename_mapping = {\n",
    "    'mlsNumber': 'mlsId',\n",
    "    'soldPrice': 'price',\n",
    "    'bath': 'baths',\n",
    "    'area': 'sqFt',\n",
    "    'built': 'yearBuilt',\n",
    "    'type': 'propertyType'\n",
    "}\n",
    "# df_cities = [process_listing(file, city, rename_mapping, select_columns) for file, city in file_city_mapping.items()]\n",
    "for file, city in file_city_mapping.items():\n",
    "    df1 = process_listing(file, city, rename_mapping, select_columns)\n",
    "\n",
    "    file_comp = file.split('-')\n",
    "    active_filename = f'{file_comp[0]}-active-listings'\n",
    "    process_active_listing(active_filename, city, rename_mapping, select_columns_active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning + Feature Manipulations\n",
    "\n",
    "Note: all code blocks below take place AFTER geocoding. Make sure geocoded csvs are in place before by executing geocode.ipynb first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import arcsin, sqrt, cos\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './data/geocoded'\n",
    "output_dir = './data/combined'\n",
    "\n",
    "# input_dir = './data/predict/geocoded'\n",
    "# output_dir = './data/predict/combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(os.path.join(input_dir, '*geocoded.csv'))\n",
    "\n",
    "csv_list = []\n",
    "for file in csv_files:\n",
    "    csv_list.append(pd.read_csv(file))\n",
    "\n",
    "df_totals = pd.concat(csv_list).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = './data/combined/total.csv'\n",
    "# out_path = './data/predict/total.csv'\n",
    "df_totals.to_csv(out_path, index = False) #totals -> total to test clean, will combine later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_centers = pd.read_csv('./data/features/cityCenters/centers.csv')\n",
    "schools = pd.read_csv('./data/features/schools/schools_total.csv')\n",
    "\n",
    "# Calculates the haversine distance between two coordinates in meters.\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    r = 6371 * 1000; # Earth's radius (m)\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    # Adapted from Wikipedia\n",
    "    return 2*r*arcsin(\n",
    "            sqrt(\n",
    "                (1-cos(lat2 - lat1) + \n",
    "                 cos(lat2)*cos(lat1) * \n",
    "                 (1 - cos(lon2 - lon1))) / 2\n",
    "                )\n",
    "            )\n",
    "\n",
    "def find_nearest_school(row):\n",
    "    distances = haversine(row['lon'], row['lat'], schools['lon'].values, schools['lat'].values)\n",
    "    nearest_index = np.argmin(distances)\n",
    "    return pd.Series({'distanceToSchool': distances[nearest_index], 'nearestSchool': schools.iloc[nearest_index]['name']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Manipulations (For Training + Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = './data/combined/total.csv'\n",
    "df = pd.read_csv(in_path)\n",
    "\n",
    "df[['listingDate', 'soldDate']] = df[['listingDate', 'soldDate']].apply(pd.to_datetime, format='mixed', dayfirst=True)\n",
    "object_columns = df.select_dtypes(include='object').columns\n",
    "\n",
    "df[object_columns] = df[object_columns].replace('', pd.NA)\n",
    "\n",
    "# geographical features\n",
    "pattern = r'^(?P<streetname>[^,]+),\\s*(?P<city>[^,]+),\\s*(?P<province>[^,]+),\\s*(?P<country>[^,]+)$'\n",
    "df[['streetAddress', 'city', 'province', 'country']] = df['address'].str.extract(pattern)\n",
    "addr_details = df['addressDetails'].str.split(', ', expand=True)\n",
    "df['neighborhood'] = df.apply(getNeighborhood, axis=1)\n",
    "df['postalCode'] = df['addressDetails'].apply(getPostalCode)\n",
    "\n",
    "# historical features\n",
    "df['yearBuilt'] = pd.to_numeric(df['yearBuilt'], errors='coerce')\n",
    "df['age'] = 2024 - df['yearBuilt']\n",
    "df['daysOnMarket'] = (df['soldDate'] - df['listingDate']).dt.days\n",
    "df = df[df['taxes'] > 0]\n",
    "df['priceToTaxRatio'] = df['price'] / df['taxes']\n",
    "df['listingYear'] = pd.to_datetime(df['listingDate']).dt.year\n",
    "df['listingMonth'] = pd.to_datetime(df['listingDate']).dt.month\n",
    "df['soldYear'] = pd.to_datetime(df['soldDate']).dt.year\n",
    "df['soldMonth'] = pd.to_datetime(df['soldDate']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(df, city_centers, on='city', how='left')\n",
    "\n",
    "# Calculate distance to the homes' respective city centers\n",
    "df['distanceToCenter'] = haversine(\n",
    "    df_tmp['lon'], df_tmp['lat'],\n",
    "    df_tmp['cityCenterLon'], df_tmp['cityCenterLat']\n",
    ")\n",
    "\n",
    "# Calculate the name and distance to the nearest school\n",
    "df[['distanceToSchool', 'nearestSchool']] = df_tmp.apply(find_nearest_school, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['mlsId', 'province', 'country', 'addressDetails'])\n",
    "df.dropna().to_csv('./data/combined/total_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning + Feature Manipulations (For Predictions)\n",
    "Again... done after geocoding portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = './data/predict/total.csv'\n",
    "df = pd.read_csv(in_path)\n",
    "\n",
    "df['listingDate'] = df['listingDate'].apply(pd.to_datetime, format='mixed', dayfirst=True)\n",
    "object_columns = df.select_dtypes(include='object').columns\n",
    "df[object_columns] = df[object_columns].replace('', pd.NA)\n",
    "\n",
    "pattern = r'^(?P<streetname>[^,]+),\\s*(?P<city>[^,]+),\\s*(?P<province>[^,]+),\\s*(?P<country>[^,]+)$'\n",
    "df[['streetAddress', 'city', 'province', 'country']] = df['address'].str.extract(pattern)\n",
    "df['neighborhood'] = df.apply(getNeighborhood, axis=1)\n",
    "df['postalCode'] = df['addressDetails'].apply(getPostalCode)\n",
    "\n",
    "df['yearBuilt'] = pd.to_numeric(df['yearBuilt'], errors='coerce')\n",
    "df['age'] = 2024 - df['yearBuilt']\n",
    "df = df[df['age'] >= 0.0]\n",
    "df = df[df['taxes'] > 0]\n",
    "df['priceToTaxRatio'] = df['listingPrice'] / df['taxes'] # we will estimate the priceToTaxRatio with the listing price\n",
    "df['listingYear'] = pd.to_datetime(df['listingDate']).dt.year\n",
    "df['listingMonth'] = pd.to_datetime(df['listingDate']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.merge(df, city_centers, on='city', how='left')\n",
    "df['distanceToCenter'] = haversine(\n",
    "    df_tmp['lon'], df_tmp['lat'],\n",
    "    df_tmp['cityCenterLon'], df_tmp['cityCenterLat']\n",
    ")\n",
    "df[['distanceToSchool', 'nearestSchool']] = df_tmp.apply(find_nearest_school, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['mlsId', 'province', 'country'])\n",
    "df.dropna().to_csv('./data/predict/total_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
